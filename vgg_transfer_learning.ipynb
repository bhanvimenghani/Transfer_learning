{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OmvoF9TPxzgzOeYRy0rYuylIflq_uaQ4",
      "authorship_tag": "ABX9TyOtYi8bNVPx/68m8zxN2ETf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanvimenghani/Transfer_learning/blob/master/vgg_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgQZBUfi9IWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4713e209-8cd0-4c4f-eeec-cd221e2a7568"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
        "img_rows = 224\n",
        "img_cols = 224 \n",
        "\n",
        "#Loads the VGG16 model \n",
        "model = VGG16(weights = 'imagenet',           #VGG takes weights from imagenet\n",
        "                 include_top = False,         #We remove the top layer(output layer) of VGG as we will make it according to our requirement\n",
        "                 input_shape = (img_rows, img_cols, 3))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0mtPF279KZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a80d47a0-cadf-4d73-ee96-b1533611d3fb"
      },
      "source": [
        "for (i,layer) in enumerate(model.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D True\n",
            "2 Conv2D True\n",
            "3 MaxPooling2D True\n",
            "4 Conv2D True\n",
            "5 Conv2D True\n",
            "6 MaxPooling2D True\n",
            "7 Conv2D True\n",
            "8 Conv2D True\n",
            "9 Conv2D True\n",
            "10 MaxPooling2D True\n",
            "11 Conv2D True\n",
            "12 Conv2D True\n",
            "13 Conv2D True\n",
            "14 MaxPooling2D True\n",
            "15 Conv2D True\n",
            "16 Conv2D True\n",
            "17 Conv2D True\n",
            "18 MaxPooling2D True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qROrxxa99RK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3UF1yhB9RsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "2d050965-892a-4502-a9b0-eb489b9126f5"
      },
      "source": [
        "for (i,layer) in enumerate(model.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D False\n",
            "2 Conv2D False\n",
            "3 MaxPooling2D False\n",
            "4 Conv2D False\n",
            "5 Conv2D False\n",
            "6 MaxPooling2D False\n",
            "7 Conv2D False\n",
            "8 Conv2D False\n",
            "9 Conv2D False\n",
            "10 MaxPooling2D False\n",
            "11 Conv2D False\n",
            "12 Conv2D False\n",
            "13 Conv2D False\n",
            "14 MaxPooling2D False\n",
            "15 Conv2D False\n",
            "16 Conv2D False\n",
            "17 Conv2D False\n",
            "18 MaxPooling2D False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHusC5RA9T5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addTopModel(bottom_model, num_classes, D=256):       #D is dimensions\n",
        "    \"\"\"Creates the top or head of the model that will be \n",
        "    placed ontop of the bottom layers\"\"\"\n",
        "    top_model = bottom_model.output\n",
        "    top_model = Flatten(name = \"flatten\")(top_model)       #Way of adding layers ; Efficient way\n",
        "    top_model = Dense(D, activation = \"relu\")(top_model)\n",
        "    top_model = Dropout(0.3)(top_model)                    #Dropout fn is for the change of 2 that comes after convolution\n",
        "    top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
        "    return top_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O69_JOKz9YGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "711533fe-f837-4ac5-a67d-c96c7d0759cb"
      },
      "source": [
        "model.input"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM1u4eJ29aUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "61b6c645-67d1-4494-ee96-1147d3ee81c8"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f6cfc47ff98>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cba139400>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cba139668>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f6cba139c18>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cba139a90>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb98f8eb8>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f6cb9902518>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb9902358>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb9902f60>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb9908be0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f6cb9910668>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb99104a8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb9910f98>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb3bedd30>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f6cb3bf57b8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb3bf55f8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb3bfe320>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f6cb3bfee80>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f6cb3c04908>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZjmmdBv9bci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "d1c62a96-2f12-46a1-9021-43c2d1978c53"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "num_classes = 2               #For 2 types of faces\n",
        "\n",
        "FC_Head = addTopModel(model, num_classes)\n",
        "\n",
        "modelnew = Model(inputs=model.input, outputs=FC_Head)    #Compile\n",
        "\n",
        "print(modelnew.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 21,137,986\n",
            "Trainable params: 6,423,298\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJhsJERt9eNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cd527913-c2a2-45f6-9384-ba07eb27bcdf"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/Train'\n",
        "validation_data_dir = '/content/drive/My Drive/Test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 16\n",
        "val_batchsize = 10\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 200 images belonging to 2 classes.\n",
            "Found 94 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLYBg0WH-zRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "bb42054d-d809-4e3c-98ee-0320e48049e2"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "                   \n",
        "checkpoint = ModelCheckpoint(\"faces_VGG16.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint]\n",
        "\n",
        "# Note we use a very small learning rate \n",
        "modelnew.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = RMSprop(lr = 0.001),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#nb_train_samples = 1190\n",
        "#nb_validation_samples = 170\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "history = modelnew.fit_generator(\n",
        "    train_generator,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 293s 1s/step - loss: 2.8581 - accuracy: 0.7100 - val_loss: 3.9964 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.99642, saving model to faces_VGG16.h5\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 151s 755ms/step - loss: 0.9698 - accuracy: 0.8100 - val_loss: 1.5477 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.99642 to 1.54770, saving model to faces_VGG16.h5\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 148s 740ms/step - loss: 0.8087 - accuracy: 0.8500 - val_loss: 3.6965 - val_accuracy: 0.8830\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.54770\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 148s 738ms/step - loss: 0.5914 - accuracy: 0.8550 - val_loss: 0.1266 - val_accuracy: 0.8404\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.54770 to 0.12660, saving model to faces_VGG16.h5\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 148s 738ms/step - loss: 0.5467 - accuracy: 0.8850 - val_loss: 4.1770 - val_accuracy: 0.9468\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.12660\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 147s 737ms/step - loss: 0.5737 - accuracy: 0.8900 - val_loss: 6.3434 - val_accuracy: 0.8404\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.12660\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 148s 738ms/step - loss: 0.5752 - accuracy: 0.8600 - val_loss: 0.2850 - val_accuracy: 0.8511\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.12660\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEgynXES-6OS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0222134f-1817-4dc7-802a-824e126c92a6"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bhan': 0, 'mom': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMI33m2d_Po0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking the model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n13SBfJ_FbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92090986-435e-4e2b-952e-056aef031aa1"
      },
      "source": [
        "#Predicting an image\n",
        "\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/My Drive/Test/bhan/image13.jpg', target_size=(224,224))\n",
        "\n",
        "import numpy as np\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = modelnew.predict(test_image)\n",
        "result"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0847601e-32, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V32x-GLpD6BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c72dff0f-cbcf-4627-fd8a-1da33487e14f"
      },
      "source": [
        "if result[0][0] == 0 :\n",
        "    print(\"Hello Mummyji\")\n",
        "else :\n",
        "    print(\"Hello Bhanvi\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Bhanvi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjh5rmmZEDw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}